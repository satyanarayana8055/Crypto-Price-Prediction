
services:
  postgres:
    image: postgres:13
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck: 
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 5

  airflow-webserver:
    build: .
    depends_on:
      postgres:
        condition: service_healthy
    env_file:
      - .env
    environment:
      SERVICE_TYPE: airflow-webserver
      PYTHONPATH: /app:/app/src   
      AIRFLOW_HOME: /app/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      AIRFLOW__CORE__DAGS_FOLDER: /app/dags
      FLASK_SECRET_KEY: ${FLASK_SECRET_KEY}
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8080

    ports:
      - "8080:8080" 
    volumes:
      - ./dags:/app/dags
      - ./airflow/logs:/app/airflow/logs
      - ./src:/app/src
      - ./data:/app/data
      - ./airflow:/app/airflow 
      - ./pipeline_config.yaml:/app/pipeline_config.yaml
    healthcheck: 
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s 
      retries: 5

  airflow-scheduler:
    build: .
    depends_on:
      postgres:
        condition: service_healthy
      airflow-webserver:
        condition: service_started
    env_file:
      - .env
    environment:
      SERVICE_TYPE: airflow-scheduler
      AIRFLOW_HOME: /app/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      AIRFLOW__CORE__DAGS_FOLDER: /app/dags
      PYTHONPATH: /app:/app/src
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8080

    volumes:
      - ./dags:/app/dags
      - ./airflow/logs:/app/airflow/logs
      - ./src:/app/src
      - ./data:/app/data
      - ./airflow:/app/airflow
      - ./pipeline_config.yaml:/app/pipeline_config.yaml

    healthcheck: 
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob  --hostname $(hostname)"]
      interval: 30s
      timeout: 10s 
      retries: 5
      
  flask:
    build: .
    depends_on:
      postgres:
        condition: service_healthy
    env_file:
      - .env
    environment:
      SERVICE_TYPE: flask
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ${DB_NAME}
      FLASK_SECRET_KEY: ${FLASK_SECRET_KEY}
      FLASK_DEBUG: 0

    ports:
      - "5000:5000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./src:/app/src

  mlflow:
    build: .
    depends_on:
      postgres:
        condition: service_healthy
    container_name: mlflow
    env_file:
      - .env
    environment:
      SERVICE_TYPE: mlflow
      MLFLOW_TRACKING_URI: http://localhost:5001
      BACKEND_STORE_URI: postgresql+psycopg2://${ML_USER}:${ML_PASSWORD}@postgres:5432/${ML_NAME}
      ARTIFACT_ROOT: /app/mlruns
    
    ports:
      - "5001:5001"
    volumes:
      - mlflow_data:/app/mlruns
    healthcheck: 
      test: ["CMD-SHELL", "curl", "-f", "http://localhost:5001"]
      interval: 30s
      timeout: 10s 
      retries: 5
volumes:
  postgres_data:
  mlflow_data: